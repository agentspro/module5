"""
–ü–û–†–Ü–í–ù–Ø–ù–ù–Ø: LangChain v0.x ‚Üí v1.0
–ü–æ–∫–∞–∑—É—î —â–æ –∑–º—ñ–Ω–∏–ª–æ—Å—å —ñ —á–æ–º—É —Ü–µ –≤–∞–∂–ª–∏–≤–æ

–ü–†–û–ë–õ–ï–ú–ê: –í v0.x –±—É–ª–æ —Å–∫–ª–∞–¥–Ω–æ –∫–æ–º–ø–æ–∑—É–≤–∞—Ç–∏ –ª–∞–Ω—Ü—é–≥–∏, –±–∞–≥–∞—Ç–æ boilerplate –∫–æ–¥—É
–†–Ü–®–ï–ù–ù–Ø: v1.0 –≤–≤–æ–¥–∏—Ç—å LCEL - –ø—Ä–æ—Å—Ç–∏–π —ñ –∑—Ä–æ–∑—É–º—ñ–ª–∏–π —Å–ø–æ—Å—ñ–± –∫–æ–º–ø–æ–∑–∏—Ü—ñ—ó
"""

from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from dotenv import load_dotenv

load_dotenv()


print("=" * 80)
print("–ú–Ü–ì–†–ê–¶–Ü–Ø: –ü–æ–±—É–¥–æ–≤–∞ –ª–∞–Ω—Ü—é–≥—ñ–≤ LangChain v0.x ‚Üí v1.0")
print("=" * 80 + "\n")


# ============================================================================
# –ü–†–ò–ö–õ–ê–î 1: –ü—Ä–æ—Å—Ç–∏–π –ª–∞–Ω—Ü—é–≥
# ============================================================================

print("\n" + "=" * 80)
print("1. –ü–†–û–°–¢–ò–ô –õ–ê–ù–¶–Æ–ì: Prompt ‚Üí Model ‚Üí Output")
print("=" * 80 + "\n")

print("‚ùå –°–¢–ê–†–ò–ô –°–ü–û–°–Ü–ë (v0.x) - Verbose, –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª–æ")
print("-" * 80)
print("""
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

# –ë–∞–≥–∞—Ç–æ boilerplate –∫–æ–¥—É
prompt = PromptTemplate(
    input_variables=["topic"],
    template="–†–æ–∑–∫–∞–∂–∏ –ø—Ä–æ {topic}"
)
llm = OpenAI(temperature=0.7)
chain = LLMChain(llm=llm, prompt=prompt)

# –í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è —á–µ—Ä–µ–∑ .run() –∞–±–æ .predict()
result = chain.run(topic="Python")  # Deprecated!
# –ê–ë–û
result = chain.predict(topic="Python")  # –ù–µ —ñ–Ω—Ç—É—ó—Ç–∏–≤–Ω–æ!
""")

print("\n‚úÖ –ù–û–í–ò–ô –°–ü–û–°–Ü–ë (v1.0) - LCEL –∑ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º |")
print("-" * 80)
print("""
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# –ü—Ä–æ—Å—Ç–æ —ñ –∑—Ä–æ–∑—É–º—ñ–ª–æ - —è–∫ Unix pipes!
prompt = ChatPromptTemplate.from_template("–†–æ–∑–∫–∞–∂–∏ –ø—Ä–æ {topic}")
model = ChatOpenAI(model="gpt-3.5-turbo")
output_parser = StrOutputParser()

chain = prompt | model | output_parser

# –Ñ–¥–∏–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å—å–æ–≥–æ
result = chain.invoke({"topic": "Python"})
""")

print("\nüéØ –©–û –ü–û–ö–†–ê–©–ò–õ–û–°–¨:")
print("  ‚Ä¢ –û–ø–µ—Ä–∞—Ç–æ—Ä | —Ä–æ–±–∏—Ç—å –∫–æ–º–ø–æ–∑–∏—Ü—ñ—é —ñ–Ω—Ç—É—ó—Ç–∏–≤–Ω–æ—é (—è–∫ bash pipes)")
print("  ‚Ä¢ –Ñ–¥–∏–Ω–∏–π –º–µ—Ç–æ–¥ .invoke() –∑–∞–º—ñ—Å—Ç—å .run(), .predict(), __call__()")
print("  ‚Ä¢ –ú–µ–Ω—à–µ –∫–æ–¥—É, –ø—Ä–æ—Å—Ç—ñ—à–µ —á–∏—Ç–∞—Ç–∏")
print("  ‚Ä¢ Runnable —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å: invoke, stream, batch - –≤—Å–µ –ø—Ä–∞—Ü—é—î –æ–¥–Ω–∞–∫–æ–≤–æ\n")

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –Ω–æ–≤–æ–≥–æ –ø—ñ–¥—Ö–æ–¥—É
model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
prompt = ChatPromptTemplate.from_template("–û–¥–Ω–µ —Ä–µ—á–µ–Ω–Ω—è –ø—Ä–æ {topic}")
chain = prompt | model | StrOutputParser()

result = chain.invoke({"topic": "–ø–µ—Ä–µ–≤–∞–≥–∏ LCEL"})
print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}\n")


# ============================================================================
# –ü–†–ò–ö–õ–ê–î 2: –ü–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ –ª–∞–Ω—Ü—é–≥–∏
# ============================================================================

print("\n" + "=" * 80)
print("2. –ü–û–°–õ–Ü–î–û–í–ù–Ü –õ–ê–ù–¶–Æ–ì–ò: –û–¥–∏–Ω –ª–∞–Ω—Ü—é–≥ ‚Üí —ñ–Ω—à–∏–π –ª–∞–Ω—Ü—é–≥")
print("=" * 80 + "\n")

print("‚ùå –°–¢–ê–†–ò–ô –°–ü–û–°–Ü–ë (v0.x) - –ü–æ—Ç—Ä—ñ–±–Ω—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –∫–ª–∞—Å–∏")
print("-" * 80)
print("""
from langchain.chains import SimpleSequentialChain, LLMChain

# –°—Ç–≤–æ—Ä—é—î–º–æ –æ–∫—Ä–µ–º—ñ –ª–∞–Ω—Ü—é–≥–∏
chain1 = LLMChain(llm=llm, prompt=prompt1)
chain2 = LLMChain(llm=llm, prompt=prompt2)

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π –∫–ª–∞—Å –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è
overall_chain = SimpleSequentialChain(
    chains=[chain1, chain2],
    verbose=True
)

result = overall_chain.run(input_text)
""")

print("\n‚úÖ –ù–û–í–ò–ô –°–ü–û–°–Ü–ë (v1.0) - –ü—Ä–æ—Å—Ç–æ –¥–æ–¥–∞—î–º–æ | –º—ñ–∂ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏")
print("-" * 80)
print("""
# –ü—Ä–æ—Å—Ç–æ –∑'—î–¥–Ω—É—î–º–æ pipe –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º
prompt1 = ChatPromptTemplate.from_template("–ì–µ–Ω–µ—Ä—É–π —ñ–¥–µ—é –¥–ª—è: {topic}")
prompt2 = ChatPromptTemplate.from_template("–ü–æ–∫—Ä–∞—â–∏ —Ü—é —ñ–¥–µ—é: {idea}")

chain = (
    prompt1
    | model
    | StrOutputParser()
    | (lambda idea: {"idea": idea})  # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –¥–ª—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
    | prompt2
    | model
    | StrOutputParser()
)

result = chain.invoke({"topic": "—Å—Ç–∞—Ä—Ç–∞–ø"})
""")

print("\nüéØ –©–û –ü–û–ö–†–ê–©–ò–õ–û–°–¨:")
print("  ‚Ä¢ –ù–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –∫–ª–∞—Å–∏ (SimpleSequentialChain, SequentialChain)")
print("  ‚Ä¢ –í—ñ–∑—É–∞–ª—å–Ω–æ –≤–∏–¥–Ω–æ –ø–æ—Ç—ñ–∫ –¥–∞–Ω–∏—Ö –∑–≤–µ—Ä—Ö—É –≤–Ω–∏–∑")
print("  ‚Ä¢ –õ–µ–≥–∫–æ –¥–æ–¥–∞–≤–∞—Ç–∏/–≤–∏–¥–∞–ª—è—Ç–∏ –∫—Ä–æ–∫–∏")
print("  ‚Ä¢ –ú–æ–∂–Ω–∞ –≤—Å—Ç–∞–≤–ª—è—Ç–∏ lambda —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö\n")


# ============================================================================
# –ü–†–ò–ö–õ–ê–î 3: –ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
# ============================================================================

print("\n" + "=" * 80)
print("3. –ü–ê–†–ê–õ–ï–õ–¨–ù–ï –í–ò–ö–û–ù–ê–ù–ù–Ø: –ö—ñ–ª—å–∫–∞ –æ–ø–µ—Ä–∞—Ü—ñ–π –æ–¥–Ω–æ—á–∞—Å–Ω–æ")
print("=" * 80 + "\n")

print("‚ùå –°–¢–ê–†–ò–ô –°–ü–û–°–Ü–ë (v0.x) - –°–∫–ª–∞–¥–Ω–æ —ñ –Ω–µ –æ—á–µ–≤–∏–¥–Ω–æ")
print("-" * 80)
print("""
import asyncio

# –ü–æ—Ç—Ä—ñ–±–Ω–æ –≤—Ä—É—á–Ω—É –∫–µ—Ä—É–≤–∞—Ç–∏ async –≤–∏–∫–ª–∏–∫–∞–º–∏
async def run_parallel():
    results = await asyncio.gather(
        chain1.arun(input1),
        chain2.arun(input2),
        chain3.arun(input3)
    )
    return results

# –ê–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ router chains –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ—é –ª–æ–≥—ñ–∫–æ—é
""")

print("\n‚úÖ –ù–û–í–ò–ô –°–ü–û–°–Ü–ë (v1.0) - RunnableParallel")
print("-" * 80)
print("""
from langchain_core.runnables import RunnableParallel

prompt1 = ChatPromptTemplate.from_template("–ü–µ—Ä–µ–≤–∞–≥–∏ {topic}")
prompt2 = ChatPromptTemplate.from_template("–ù–µ–¥–æ–ª—ñ–∫–∏ {topic}")
prompt3 = ChatPromptTemplate.from_template("–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏ {topic}")

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ!
parallel_chain = RunnableParallel(
    pros=prompt1 | model | StrOutputParser(),
    cons=prompt2 | model | StrOutputParser(),
    alternatives=prompt3 | model | StrOutputParser()
)

result = parallel_chain.invoke({"topic": "microservices"})
# result = {"pros": "...", "cons": "...", "alternatives": "..."}
""")

print("\nüéØ –©–û –ü–û–ö–†–ê–©–ò–õ–û–°–¨:")
print("  ‚Ä¢ –ù–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤—Ä—É—á–Ω—É –∫–µ—Ä—É–≤–∞—Ç–∏ async")
print("  ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –ø–∞—Ä–∞–ª–µ–ª—ñ–∑–∞—Ü—ñ—è")
print("  ‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç —É –∑—Ä—É—á–Ω–æ–º—É dict —Ñ–æ—Ä–º–∞—Ç—ñ")
print("  ‚Ä¢ –ü—Ä–∞—Ü—é—î —ñ –≤ sync, —ñ –≤ async —Ä–µ–∂–∏–º–∞—Ö\n")

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è
model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
parallel = RunnableParallel(
    short=ChatPromptTemplate.from_template("–û–¥–Ω–µ —Å–ª–æ–≤–æ –ø—Ä–æ {topic}") | model | StrOutputParser(),
    emoji=ChatPromptTemplate.from_template("–û–¥–∏–Ω –µ–º–æ–¥–∑—ñ –¥–ª—è {topic}") | model | StrOutputParser(),
)

result = parallel.invoke({"topic": "Python"})
print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è:")
print(f"   –ö–æ—Ä–æ—Ç–∫–æ: {result['short']}")
print(f"   –ï–º–æ–¥–∑—ñ: {result['emoji']}\n")


# ============================================================================
# –ü–†–ò–ö–õ–ê–î 4: Streaming
# ============================================================================

print("\n" + "=" * 80)
print("4. STREAMING: –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —á–∞—Å—Ç–∏–Ω–∞–º–∏")
print("=" * 80 + "\n")

print("‚ùå –°–¢–ê–†–ò–ô –°–ü–û–°–Ü–ë (v0.x) - –†—ñ–∑–Ω—ñ API –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤")
print("-" * 80)
print("""
# –î–ª—è LLM
for chunk in llm.stream("prompt"):
    print(chunk, end="")

# –î–ª—è Chain - —ñ–Ω—à–∏–π —Å–ø–æ—Å—ñ–±
chain = LLMChain(...)
async for chunk in chain.astream(inputs):
    print(chunk, end="")

# –ù–µ –≤—Å—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–ª–∏ streaming
""")

print("\n‚úÖ –ù–û–í–ò–ô –°–ü–û–°–Ü–ë (v1.0) - –Ñ–¥–∏–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å .stream()")
print("-" * 80)
print("""
# –í—Å–µ —â–æ –º–∞—î Runnable —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—ñ–¥—Ç—Ä–∏–º—É—î .stream()
chain = prompt | model | StrOutputParser()

# –ü—Ä–æ—Å—Ç–æ –≤–∏–∫–ª–∏–∫–∞—î–º–æ .stream()
for chunk in chain.stream({"topic": "AI"}):
    print(chunk, end="", flush=True)

# –ü—Ä–∞—Ü—é—î –¥–ª—è –±—É–¥—å-—è–∫–æ–≥–æ –ª–∞–Ω—Ü—é–≥–∞, –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ!
""")

print("\nüéØ –©–û –ü–û–ö–†–ê–©–ò–õ–û–°–¨:")
print("  ‚Ä¢ –Ñ–¥–∏–Ω–∏–π .stream() –º–µ—Ç–æ–¥ –¥–ª—è –≤—Å—å–æ–≥–æ")
print("  ‚Ä¢ –í–µ—Å—å –ª–∞–Ω—Ü—é–≥ –ø—ñ–¥—Ç—Ä–∏–º—É—î streaming, –∞ –Ω–µ –ª–∏—à–µ LLM")
print("  ‚Ä¢ –ú–æ–∂–Ω–∞ —Å—Ç—Ä—ñ–º–∏—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏—Ö –æ–ø–µ—Ä–∞—Ü—ñ–π")
print("  ‚Ä¢ Async –≤–∞—Ä—ñ–∞–Ω—Ç: .astream()\n")


# ============================================================================
# –ü–†–ò–ö–õ–ê–î 5: Batch –æ–±—Ä–æ–±–∫–∞
# ============================================================================

print("\n" + "=" * 80)
print("5. BATCH –û–ë–†–û–ë–ö–ê: –û–±—Ä–æ–±–∫–∞ –±–∞–≥–∞—Ç—å–æ—Ö –≤—Ö–æ–¥—ñ–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ")
print("=" * 80 + "\n")

print("‚ùå –°–¢–ê–†–ò–ô –°–ü–û–°–Ü–ë (v0.x) - –í—Ä—É—á–Ω—É –≤ —Ü–∏–∫–ª—ñ –∞–±–æ apply")
print("-" * 80)
print("""
# –í—Ä—É—á–Ω—É –≤ —Ü–∏–∫–ª—ñ
results = []
for input_data in inputs:
    result = chain.run(input_data)
    results.append(result)

# –ê–±–æ —á–µ—Ä–µ–∑ apply (–Ω–µ –∑–∞–≤–∂–¥–∏ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
results = chain.apply(inputs)
""")

print("\n‚úÖ –ù–û–í–ò–ô –°–ü–û–°–Ü–ë (v1.0) - –í–±—É–¥–æ–≤–∞–Ω–∏–π .batch()")
print("-" * 80)
print("""
chain = prompt | model | StrOutputParser()

inputs = [
    {"topic": "Python"},
    {"topic": "JavaScript"},
    {"topic": "Rust"}
]

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–ø—Ç–∏–º—ñ–∑—É—î—Ç—å—Å—è –¥–ª—è batch –æ–±—Ä–æ–±–∫–∏!
results = chain.batch(inputs)
# ['–ü—Ä–æ Python...', '–ü—Ä–æ JavaScript...', '–ü—Ä–æ Rust...']
""")

print("\nüéØ –©–û –ü–û–ö–†–ê–©–ò–õ–û–°–¨:")
print("  ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ batch –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è")
print("  ‚Ä¢ –ú–µ–Ω—à–µ API –≤–∏–∫–ª–∏–∫—ñ–≤ ‚Üí —à–≤–∏–¥—à–µ —ñ –¥–µ—à–µ–≤—à–µ")
print("  ‚Ä¢ –Ñ–¥–∏–Ω–∏–π .batch() –¥–ª—è –≤—Å—ñ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤")
print("  ‚Ä¢ Async –≤–∞—Ä—ñ–∞–Ω—Ç: .abatch()\n")

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è
chain = (
    ChatPromptTemplate.from_template("–û–¥–Ω–µ —Å–ª–æ–≤–æ –ø—Ä–æ {lang}")
    | ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    | StrOutputParser()
)

inputs = [{"lang": "Python"}, {"lang": "JavaScript"}, {"lang": "Go"}]
results = chain.batch(inputs)

print("üìù Batch —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:")
for inp, res in zip(inputs, results):
    print(f"   {inp['lang']}: {res}")


# ============================================================================
# –ü–Ü–î–°–£–ú–û–ö
# ============================================================================

print("\n\n" + "=" * 80)
print("üìä –ü–Ü–î–°–£–ú–û–ö –ó–ú–Ü–ù v0.x ‚Üí v1.0")
print("=" * 80 + "\n")

print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
print("‚îÇ –©–æ —Ä–æ–±–∏–º–æ           ‚îÇ v0.x (–°—Ç–∞—Ä–µ)             ‚îÇ v1.0 (–ù–æ–≤–µ - LCEL)       ‚îÇ")
print("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
print("‚îÇ –ö–æ–º–ø–æ–∑–∏—Ü—ñ—è          ‚îÇ LLMChain, —Å–ø–µ—Ü. –∫–ª–∞—Å–∏    ‚îÇ –û–ø–µ—Ä–∞—Ç–æ—Ä |              ‚îÇ")
print("‚îÇ –í–∏–∫–ª–∏–∫              ‚îÇ .run(), .predict()       ‚îÇ .invoke()                ‚îÇ")
print("‚îÇ Streaming           ‚îÇ –†—ñ–∑–Ω—ñ API                ‚îÇ .stream()                ‚îÇ")
print("‚îÇ Batch               ‚îÇ .apply() –∞–±–æ —Ü–∏–∫–ª        ‚îÇ .batch()                 ‚îÇ")
print("‚îÇ Async               ‚îÇ .arun(), .apredict()     ‚îÇ .ainvoke(), .astream()   ‚îÇ")
print("‚îÇ –ü–∞—Ä–∞–ª–µ–ª—å–Ω—ñ—Å—Ç—å       ‚îÇ asyncio.gather()         ‚îÇ RunnableParallel         ‚îÇ")
print("‚îÇ –ß–∏—Ç–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å       ‚îÇ ‚≠ê‚≠ê –ë–∞–≥–∞—Ç–æ boilerplate   ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –î—É–∂–µ —á–∏—Å—Ç–æ      ‚îÇ")
print("‚îÇ –ü—Ä–æ—Å—Ç–æ—Ç–∞            ‚îÇ ‚≠ê‚≠ê –ü–æ—Ç—Ä—ñ–±–Ω–æ –∑–Ω–∞—Ç–∏ –∫–ª–∞—Å–∏ ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –Ü–Ω—Ç—É—ó—Ç–∏–≤–Ω–æ      ‚îÇ")
print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")

print("\nüí° –ö–õ–Æ–ß–û–í–Ü –ü–ï–†–ï–í–ê–ì–ò LCEL:")
print("  1. –Ñ–¥–∏–Ω–∏–π Runnable —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å—å–æ–≥–æ")
print("  2. –ö–æ–º–ø–æ–∑–∏—Ü—ñ—è —á–µ—Ä–µ–∑ | –æ–ø–µ—Ä–∞—Ç–æ—Ä (—è–∫ Unix pipes)")
print("  3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ sync/async/streaming/batch")
print("  4. –ú–µ–Ω—à–µ –∫–æ–¥—É, –±—ñ–ª—å—à–µ —è—Å–Ω–æ—Å—Ç—ñ")
print("  5. –õ–µ–≥—à–µ —Ç–µ—Å—Ç—É–≤–∞—Ç–∏ —Ç–∞ –¥–µ–±–∞–∂–∏—Ç–∏")
print("  6. –ö—Ä–∞—â—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –¥–ª—è —Ç—Ä–µ–π—Å–∏–Ω–≥—É (LangSmith)")

print("\n" + "=" * 80)
